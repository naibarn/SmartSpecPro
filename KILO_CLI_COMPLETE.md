# Kilo CLI Workflow Execution - à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¸à¸±à¸’à¸™à¸²à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

## ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
à¸—à¸³à¹ƒà¸«à¹‰ Desktop App à¸ªà¸²à¸¡à¸²à¸£à¸–à¸£à¸±à¸™ workflows (à¸—à¸±à¹‰à¸‡ bash à¹à¸¥à¸° AI) à¹„à¸”à¹‰à¹€à¸«à¸¡à¸·à¸­à¸™ Kilo Code extension

## âœ… à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸—à¸³à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ 100%

### 1. Bash Workflow Execution (à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š)
- âœ… à¸£à¸±à¸™ bash code blocks à¸ˆà¸²à¸ .md files
- âœ… Real-time output streaming
- âœ… à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ (UTF-8)
- âœ… Argument parsing à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (à¸£à¸­à¸‡à¸£à¸±à¸š spaces, quotes, Thai)
- âœ… Error handling à¹à¸¥à¸° exit codes

### 2. AI Workflow Detection (à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
- âœ… Auto-detect AI workflows à¸ˆà¸²à¸ frontmatter metadata
- âœ… à¸•à¸£à¸§à¸ˆà¸ˆà¸²à¸: role, write_guard, category
- âœ… à¸•à¸£à¸§à¸ˆà¸ˆà¸²à¸ bash block syntax: `[--flag]`, `<param>`
- âœ… LLM integration à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
- âœ… Error messages à¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸à¸£à¹‰à¸­à¸¡à¹à¸™à¸°à¸™à¸³à¸§à¸´à¸˜à¸µà¹à¸à¹‰

### 3. Infrastructure
- âœ… Job manager: process spawning, stdout/stderr capture
- âœ… Stream API: Server-Sent Events (NDJSON format)
- âœ… Frontend: Real-time terminal display
- âœ… Authentication: Bearer token support

---

## ğŸ“‹ à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹à¸à¹‰à¹„à¸‚

### Backend (Python)

#### 1. `python-backend/app/kilo/job_manager.py`
```python
# Line 3: à¹€à¸à¸´à¹ˆà¸¡ import
import shlex

# Line 59-61: à¹ƒà¸Šà¹‰ shlex à¹à¸¥à¸°à¹€à¸à¸´à¹ˆà¸¡ -u flag
command_args = shlex.split(command)
argv = [python_exe, "-u", "-m", "ss_autopilot.cli_enhanced"] + command_args
```

**à¹€à¸«à¸•à¸¸à¸œà¸¥:**
- `shlex.split()`: à¹à¸¢à¸ arguments à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (à¸£à¸­à¸‡à¸£à¸±à¸š quotes à¹à¸¥à¸°à¸ à¸²à¸©à¸²à¹„à¸—à¸¢)
- `-u` flag: unbuffer Python output (real-time streaming)

#### 2. `.smartspec/ss_autopilot/cli_enhanced.py`
```python
# Line 16: à¹€à¸à¸´à¹ˆà¸¡ import
import os
import yaml

# Line 586-676: à¹€à¸à¸´à¹ˆà¸¡ workflow detection à¹à¸¥à¸° LLM integration
- Parse frontmatter (YAML)
- Detect AI workflows
- Call LLMClient for AI workflows
- Execute bash blocks for bash workflows
- Improved error messages
```

**à¹€à¸«à¸•à¸¸à¸œà¸¥:**
- à¹à¸¢à¸ workflow types: bash vs AI
- Auto-detection à¸ˆà¸²à¸ metadata
- LLM integration à¸ªà¸³à¸«à¸£à¸±à¸š AI workflows

### Frontend (TypeScript/React)

#### 3. `desktop-app/src/services/kiloCli.ts`
```typescript
// Line 27-34: à¹€à¸à¸´à¹ˆà¸¡à¸Ÿà¸´à¸¥à¸”à¹Œ data
export type StreamMessage = {
  type: "stdout" | "done" | "error" | "status" | string;
  seq: number;
  line?: string;
  data?: string;  // Backend sends 'data' field for stdout
  status?: string;
  returncode?: number;
  message?: string;
};
```

**à¹€à¸«à¸•à¸¸à¸œà¸¥:**
- Backend à¸ªà¹ˆà¸‡ `data` field
- Frontend à¸•à¹‰à¸­à¸‡à¸£à¸­à¸‡à¸£à¸±à¸šà¸—à¸±à¹‰à¸‡ `data` à¹à¸¥à¸° `line` (backward compatibility)

#### 4. `desktop-app/src/pages/KiloCli.tsx`
```typescript
// Line 111-125: à¹à¸à¹‰ handler
if (m.type === "stdout") {
  setLastSeq(m.seq);
  const text = m.data || m.line || "";
  append(text);
} else if (m.type === "status") {
  setStatus(m.status || "done");
  append(`\n[done] status=${m.status} rc=${m.returncode}\n`);
} else if (m.type === "error") {
  setStatus("error");
  append(`\n[error] ${m.message}\n`);
}
```

**à¹€à¸«à¸•à¸¸à¸œà¸¥:**
- à¸­à¹ˆà¸²à¸™ `m.data` à¸à¹ˆà¸­à¸™ fallback à¹„à¸› `m.line`
- à¸£à¸­à¸‡à¸£à¸±à¸š type "status" à¹à¸¥à¸° "error"

---

## ğŸ”§ à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸£à¸°à¸šà¸š

### Bash Workflow Flow

```
User: /test_hello.md à¸ªà¸§à¸±à¸ªà¸”à¸µ
  â†“
Desktop App: kiloRun(workspace, command)
  â†“
Backend: POST /api/v1/kilo/run
  â†“
Job Manager: 
  - shlex.split("/test_hello.md à¸ªà¸§à¸±à¸ªà¸”à¸µ")
  - spawn: python3 -u -m ss_autopilot.cli_enhanced /test_hello.md à¸ªà¸§à¸±à¸ªà¸”à¸µ
  â†“
CLI (cli_enhanced.py):
  - Detect workflow type (bash)
  - Extract bash code blocks
  - Execute with subprocess.run()
  â†“
Job Manager: Capture stdout line-by-line
  â†“
Backend: GET /api/v1/kilo/jobs/{jobId}/events
  - Stream: {"type":"stdout","seq":1,"data":"ğŸ‰ Kilo CLI à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¹à¸¥à¹‰à¸§!\n"}
  â†“
Desktop App: Display in terminal real-time
```

### AI Workflow Flow

```
User: /smartspec_project_copilot.md "à¸§à¸´à¸˜à¸µà¸•à¸´à¸”à¸•à¸±à¹‰à¸‡"
  â†“
CLI: Detect AI workflow (from frontmatter)
  â†“
CLI: Build LLM messages
  - System: workflow content
  - User: "à¸§à¸´à¸˜à¸µà¸•à¸´à¸”à¸•à¸±à¹‰à¸‡"
  â†“
CLI: Call LLMClient.chat()
  â†“
Backend: POST /v1/chat/completions
  â†“
LLM Provider: Process and respond
  â†“
CLI: Display response
```

---

## ğŸ§ª à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š

### à¸—à¸”à¸ªà¸­à¸š Bash Workflow

**à¹ƒà¸™ Desktop App:**
```
Command: /test_hello.md à¸ªà¸§à¸±à¸ªà¸”à¸µ
```

**Expected Output:**
```
ğŸ” Executing workflow: test_hello
ğŸ“ Additional arguments: à¸ªà¸§à¸±à¸ªà¸”à¸µ
âœ… Found workflow: /home/naibarn/projects/SmartSpecPro/.smartspec/workflows/test_hello.md
ğŸ“¦ Found 1 bash code blocks

ğŸ”¨ Executing block 1:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
=========================================
ğŸ‰ Kilo CLI à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¹à¸¥à¹‰à¸§!
=========================================

Workspace: /home/naibarn/projects/SmartSpecPro

à¸£à¸²à¸¢à¸à¸²à¸£à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸™à¸µà¹‰:
[file listing...]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Workflow execution completed

[done] status=completed rc=0
```

### à¸—à¸”à¸ªà¸­à¸š AI Workflow (à¸•à¹‰à¸­à¸‡à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² provider à¸à¹ˆà¸­à¸™)

**à¹ƒà¸™ Desktop App:**
```
Command: /smartspec_project_copilot.md "à¸§à¸´à¸˜à¸µà¸•à¸´à¸”à¸•à¸±à¹‰à¸‡"
```

**Expected Output:**
```
ğŸ” Executing workflow: smartspec_project_copilot
ğŸ“ Additional arguments: à¸§à¸´à¸˜à¸µà¸•à¸´à¸”à¸•à¸±à¹‰à¸‡
âœ… Found workflow: ...
ğŸ¤– AI Workflow detected - sending to LLM

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”„ Calling LLM...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[LLM response about installation...]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… LLM response completed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[done] status=completed rc=0
```

---

## âš™ï¸ à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² LLM Provider (à¸ªà¸³à¸«à¸£à¸±à¸š AI Workflows)

### à¸›à¸±à¸à¸«à¸²à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™
```
âŒ Error calling LLM: Gateway error: LLM call failed: Provider anthropic not available

ğŸ’¡ LLM Provider not configured. Please configure one of:
   1. OpenRouter: Set OPENROUTER_API_KEY in .env
   2. OpenAI: Set OPENAI_API_KEY in .env
   3. SmartSpecWeb Gateway: Enable SMARTSPEC_USE_WEB_GATEWAY
```

### à¸§à¸´à¸˜à¸µà¹à¸à¹‰ (à¹€à¸¥à¸·à¸­à¸ 1 à¸§à¸´à¸˜à¸µ)

#### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1: à¹ƒà¸Šà¹‰ OpenRouter (à¹à¸™à¸°à¸™à¸³)

1. à¸ªà¸¡à¸±à¸„à¸£ OpenRouter: https://openrouter.ai/
2. à¹€à¸à¸´à¹ˆà¸¡à¹ƒà¸™ `python-backend/.env`:
```bash
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxx
USE_OPENROUTER=true
```
3. à¸£à¸µà¸ªà¸•à¸²à¸£à¹Œà¸— backend

#### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 2: à¹ƒà¸Šà¹‰ OpenAI à¹‚à¸”à¸¢à¸•à¸£à¸‡

1. à¸ªà¸¡à¸±à¸„à¸£ OpenAI: https://platform.openai.com/
2. à¹€à¸à¸´à¹ˆà¸¡à¹ƒà¸™ `python-backend/.env`:
```bash
OPENAI_API_KEY=sk-xxxxxxxxxxxxx
```
3. à¸£à¸µà¸ªà¸•à¸²à¸£à¹Œà¸— backend

#### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 3: à¹ƒà¸Šà¹‰ SmartSpecWeb Gateway

1. à¹€à¸›à¸´à¸” SmartSpecWeb Gateway à¸—à¸µà¹ˆ port 3000
2. à¹€à¸à¸´à¹ˆà¸¡à¹ƒà¸™ `python-backend/.env`:
```bash
SMARTSPEC_USE_WEB_GATEWAY=true
SMARTSPEC_WEB_GATEWAY_URL=http://localhost:3000/api/v1/llm/openai/chat/completions
SMARTSPEC_WEB_GATEWAY_TOKEN=your_gateway_token
```
3. à¸£à¸µà¸ªà¸•à¸²à¸£à¹Œà¸— backend

---

## ğŸ“Š à¸ªà¸–à¸²à¸™à¸°à¸£à¸°à¸šà¸š

### âœ… à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹à¸¥à¹‰à¸§
- Bash workflow execution
- Real-time output streaming
- Thai language support
- Argument parsing
- Error handling
- Desktop App integration

### ğŸ”„ à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (à¸£à¸­à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²)
- AI workflow execution
- LLM integration
- Auto-detection

### ğŸ“ Environment Variables

Backend à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™:
```bash
# à¹ƒà¸™ python-backend/.env
SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026
SMARTSPEC_LOCALHOST_ONLY=false

# à¹€à¸¥à¸·à¸­à¸ 1 à¸ˆà¸²à¸ 3 options à¸ªà¸³à¸«à¸£à¸±à¸š LLM
OPENROUTER_API_KEY=sk-or-v1-...  # Option 1
# à¸«à¸£à¸·à¸­
OPENAI_API_KEY=sk-...  # Option 2
# à¸«à¸£à¸·à¸­
SMARTSPEC_USE_WEB_GATEWAY=true  # Option 3
SMARTSPEC_WEB_GATEWAY_URL=...
SMARTSPEC_WEB_GATEWAY_TOKEN=...
```

CLI Environment (auto-loaded by Job Manager):
```bash
PYTHONPATH=.smartspec:$PYTHONPATH
SMARTSPEC_BACKEND_URL=http://localhost:8000
SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026
```

---

## ğŸš€ à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰à¸‡à¸²à¸™

### 1. à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

```bash
# Start backend
cd python-backend
.venv/bin/python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Start Desktop App
cd desktop-app
npm run tauri dev
```

### 2. à¹ƒà¸™ Desktop App

1. à¹„à¸›à¸—à¸µà¹ˆà¸«à¸™à¹‰à¸² "Kilo CLI"
2. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² workspace: `/home/naibarn/projects/SmartSpecPro`
3. à¸à¸´à¸¡à¸à¹Œà¸„à¸³à¸ªà¸±à¹ˆà¸‡ à¹€à¸Šà¹ˆà¸™:
   - `/test_hello.md à¸ªà¸§à¸±à¸ªà¸”à¸µ`
   - `/smartspec_project_copilot.md "à¸„à¸³à¸–à¸²à¸¡"`
4. à¸à¸” "Run"
5. à¸”à¸¹ output à¹à¸šà¸š real-time

---

## ğŸ› Troubleshooting

### à¸›à¸±à¸à¸«à¸²: à¹„à¸¡à¹ˆà¸¡à¸µ output à¹à¸ªà¸”à¸‡

**à¸ªà¸²à¹€à¸«à¸•à¸¸:**
- Frontend à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸£à¸µà¹‚à¸«à¸¥à¸”
- Backend à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£ unbuffer

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
1. à¸£à¸µà¹‚à¸«à¸¥à¸” Desktop App (Ctrl+R)
2. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² backend à¸¡à¸µ `-u` flag à¹ƒà¸™ job_manager.py:61
3. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² Frontend à¸­à¹ˆà¸²à¸™ `m.data` à¹ƒà¸™ KiloCli.tsx:113

### à¸›à¸±à¸à¸«à¸²: Bash blocks execute à¹à¸•à¹ˆ error

**à¸ªà¸²à¹€à¸«à¸•à¸¸:**
- Bash syntax à¸œà¸´à¸”
- Workflow à¹€à¸›à¹‡à¸™ documentation à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ executable script

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² bash blocks à¸¡à¸µ syntax à¸—à¸µà¹ˆ run à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡
2. à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™ AI workflow à¹à¸•à¹ˆà¸–à¸¹à¸ detect à¹€à¸›à¹‡à¸™ bash â†’ à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² LLM provider

### à¸›à¸±à¸à¸«à¸²: LLM not available

**à¸ªà¸²à¹€à¸«à¸•à¸¸:**
- à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² provider API key
- Provider à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š model à¸—à¸µà¹ˆà¸‚à¸­

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
1. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² API key à¸•à¸²à¸¡à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸”à¹‰à¸²à¸™à¸šà¸™
2. à¸£à¸µà¸ªà¸•à¸²à¸£à¹Œà¸— backend
3. à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆ

---

## ğŸ“š à¸ªà¸£à¸¸à¸›

**Kilo CLI System à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸šà¹à¸¥à¹‰à¸§!**

- âœ… Bash workflows: à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰ 100%
- âœ… AI workflows: à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¸£à¸­à¹à¸„à¹ˆà¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² LLM provider
- âœ… Real-time streaming: à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸”à¸µ
- âœ… Thai language: à¸£à¸­à¸‡à¸£à¸±à¸šà¸„à¸£à¸šà¸–à¹‰à¸§à¸™
- âœ… Error handling: à¸Šà¸±à¸”à¹€à¸ˆà¸™à¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸–à¸±à¸”à¹„à¸› (à¸–à¹‰à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰ AI workflows):**
1. à¹€à¸¥à¸·à¸­à¸ LLM provider (OpenRouter à¹à¸™à¸°à¸™à¸³)
2. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² API key à¹ƒà¸™ `.env`
3. à¸£à¸µà¸ªà¸•à¸²à¸£à¹Œà¸— backend
4. à¸—à¸”à¸ªà¸­à¸š AI workflow

---

**Created:** 2026-01-09
**Version:** 1.0.0
**Status:** âœ… Complete
