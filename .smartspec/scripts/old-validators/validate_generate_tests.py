#!/usr/bin/env python3
"""
Validate Generate Tests - SmartSpec Workflow Validator

Validates test specifications generated by generate_tests workflow to ensure:
- Comprehensive test coverage
- Clear test cases and scenarios
- Proper test structure
- Acceptance criteria defined
- Edge cases covered
- Naming conventions followed

Auto-fixes common issues when possible.
"""

import json
import sys
import re
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional

class GenerateTestsValidator:
    """Validator for generate_tests workflow output"""
    
    # Required sections in a test specification
    REQUIRED_SECTIONS = [
        "overview",
        "test_strategy",
        "test_cases",
        "test_data",
        "acceptance_criteria"
    ]
    
    # Optional but recommended sections
    RECOMMENDED_SECTIONS = [
        "edge_cases",
        "performance_tests",
        "security_tests",
        "integration_tests",
        "regression_tests",
        "test_environment"
    ]
    
    # Test case required fields
    TEST_CASE_FIELDS = [
        "id",
        "description",
        "preconditions",
        "steps",
        "expected_result"
    ]
    
    def __init__(self, test_file: Path, repo_root: Optional[Path] = None):
        """
        Initialize validator
        
        Args:
            test_file: Path to test file
            repo_root: Repository root for validating paths
        """
        self.test_file = Path(test_file)
        self.repo_root = Path(repo_root) if repo_root else self.test_file.parent
        self.issues = []
        self.fixes_applied = []
        self.test_data = None
        
    def load_tests(self) -> bool:
        """Load test file"""
        try:
            if self.test_file.suffix == '.json':
                with open(self.test_file, 'r', encoding='utf-8') as f:
                    self.test_data = json.load(f)
            elif self.test_file.suffix == '.md':
                self.test_data = self._parse_markdown()
            else:
                self.issues.append({
                    'type': 'error',
                    'message': f'Unsupported file type: {self.test_file.suffix}',
                    'fixable': False
                })
                return False
            return True
        except Exception as e:
            self.issues.append({
                'type': 'error',
                'message': f'Failed to load tests: {str(e)}',
                'fixable': False
            })
            return False
    
    def _parse_markdown(self) -> Dict[str, Any]:
        """Parse markdown test spec into structured data"""
        with open(self.test_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        tests = {}
        current_section = None
        current_content = []
        
        for line in content.split('\n'):
            if line.startswith('## '):
                if current_section:
                    tests[current_section] = '\n'.join(current_content).strip()
                current_section = line[3:].strip().lower().replace(' ', '_')
                current_content = []
            elif current_section:
                current_content.append(line)
        
        if current_section:
            tests[current_section] = '\n'.join(current_content).strip()
        
        return tests
    
    def validate_structure(self) -> None:
        """Validate test structure"""
        if not isinstance(self.test_data, dict):
            self.issues.append({
                'type': 'error',
                'message': 'Test spec must be a dictionary/object',
                'fixable': False
            })
            return
        
        # Check required sections
        for section in self.REQUIRED_SECTIONS:
            if section not in self.test_data:
                self.issues.append({
                    'type': 'error',
                    'section': section,
                    'message': f'Missing required section: {section}',
                    'fixable': True,
                    'fix': 'add_section'
                })
            elif not self.test_data[section] or not str(self.test_data[section]).strip():
                self.issues.append({
                    'type': 'warning',
                    'section': section,
                    'message': f'Section "{section}" is empty',
                    'fixable': True,
                    'fix': 'add_placeholder'
                })
        
        # Check recommended sections
        for section in self.RECOMMENDED_SECTIONS:
            if section not in self.test_data:
                self.issues.append({
                    'type': 'info',
                    'section': section,
                    'message': f'Recommended section missing: {section}',
                    'fixable': True,
                    'fix': 'add_section'
                })
    
    def validate_test_strategy(self) -> None:
        """Validate test strategy section"""
        if 'test_strategy' not in self.test_data:
            return
        
        strategy = str(self.test_data['test_strategy'])
        
        # Check for test types
        test_types = ['unit', 'integration', 'e2e', 'performance', 'security', 'regression']
        found_types = [t for t in test_types if t in strategy.lower()]
        
        if len(found_types) < 2:
            self.issues.append({
                'type': 'warning',
                'section': 'test_strategy',
                'message': f'Only {len(found_types)} test type(s) mentioned (found: {", ".join(found_types)})',
                'fixable': False
            })
        
        # Check for coverage mention
        has_coverage = 'coverage' in strategy.lower()
        
        if not has_coverage:
            self.issues.append({
                'type': 'info',
                'section': 'test_strategy',
                'message': 'No test coverage target mentioned',
                'fixable': False
            })
    
    def validate_test_cases(self) -> None:
        """Validate test cases section"""
        if 'test_cases' not in self.test_data:
            return
        
        test_cases = str(self.test_data['test_cases'])
        
        # Check for test case IDs
        test_id_patterns = [
            r'TC[-_]\d+',  # TC-001, TC_001
            r'TEST[-_]\d+',  # TEST-001
            r'T\d{3,}',  # T001
        ]
        
        found_ids = []
        for pattern in test_id_patterns:
            matches = re.findall(pattern, test_cases, re.IGNORECASE)
            found_ids.extend(matches)
        
        if len(found_ids) < 3:
            self.issues.append({
                'type': 'warning',
                'section': 'test_cases',
                'message': f'Only {len(found_ids)} test case(s) found (recommend 3+)',
                'fixable': False
            })
        
        # Check for test case structure
        has_steps = 'step' in test_cases.lower()
        has_expected = 'expected' in test_cases.lower()
        has_actual = 'actual' in test_cases.lower()
        
        if not has_steps:
            self.issues.append({
                'type': 'warning',
                'section': 'test_cases',
                'message': 'Test cases missing step definitions',
                'fixable': False
            })
        
        if not has_expected:
            self.issues.append({
                'type': 'warning',
                'section': 'test_cases',
                'message': 'Test cases missing expected results',
                'fixable': False
            })
    
    def validate_test_data(self) -> None:
        """Validate test data section"""
        if 'test_data' not in self.test_data:
            return
        
        test_data = str(self.test_data['test_data'])
        
        # Check for data types
        data_keywords = ['input', 'output', 'mock', 'fixture', 'sample', 'example']
        found_keywords = [k for k in data_keywords if k in test_data.lower()]
        
        if len(found_keywords) < 2:
            self.issues.append({
                'type': 'info',
                'section': 'test_data',
                'message': f'Test data may be incomplete (found: {", ".join(found_keywords)})',
                'fixable': False
            })
        
        # Check for data formats
        data_formats = ['json', 'csv', 'xml', 'yaml']
        has_format = any(fmt in test_data.lower() for fmt in data_formats)
        
        if not has_format:
            self.issues.append({
                'type': 'info',
                'section': 'test_data',
                'message': 'No specific data format mentioned',
                'fixable': False
            })
    
    def validate_acceptance_criteria(self) -> None:
        """Validate acceptance criteria section"""
        if 'acceptance_criteria' not in self.test_data:
            return
        
        criteria = str(self.test_data['acceptance_criteria'])
        
        # Check for criteria definitions
        criteria_patterns = [
            r'(?:^|\n)[-*]\s+(.+)',  # Bullet points
            r'(?:^|\n)\d+\.\s+(.+)',  # Numbered list
        ]
        
        found_criteria = []
        for pattern in criteria_patterns:
            matches = re.findall(pattern, criteria, re.MULTILINE)
            found_criteria.extend(matches)
        
        if len(found_criteria) < 3:
            self.issues.append({
                'type': 'warning',
                'section': 'acceptance_criteria',
                'message': f'Only {len(found_criteria)} acceptance criterion/criteria found (recommend 3+)',
                'fixable': False
            })
        
        # Check for measurable criteria
        measurable_keywords = ['must', 'should', 'shall', 'will', '%', 'seconds', 'ms']
        has_measurable = any(keyword in criteria.lower() for keyword in measurable_keywords)
        
        if not has_measurable:
            self.issues.append({
                'type': 'info',
                'section': 'acceptance_criteria',
                'message': 'Acceptance criteria may lack measurable targets',
                'fixable': False
            })
    
    def validate_edge_cases(self) -> None:
        """Validate edge cases section"""
        if 'edge_cases' not in self.test_data:
            return
        
        edge_cases = str(self.test_data['edge_cases'])
        
        # Check for edge case types
        edge_types = ['null', 'empty', 'zero', 'negative', 'maximum', 'minimum', 'boundary', 'invalid']
        found_types = [t for t in edge_types if t in edge_cases.lower()]
        
        if len(found_types) < 3:
            self.issues.append({
                'type': 'info',
                'section': 'edge_cases',
                'message': f'Only {len(found_types)} edge case type(s) covered (found: {", ".join(found_types)})',
                'fixable': False
            })
    
    def validate_performance_tests(self) -> None:
        """Validate performance tests section"""
        if 'performance_tests' not in self.test_data:
            return
        
        perf_tests = str(self.test_data['performance_tests'])
        
        # Check for performance metrics
        perf_metrics = ['response time', 'throughput', 'latency', 'load', 'stress', 'concurrent']
        found_metrics = [m for m in perf_metrics if m in perf_tests.lower()]
        
        if len(found_metrics) < 2:
            self.issues.append({
                'type': 'info',
                'section': 'performance_tests',
                'message': f'Limited performance metrics (found: {", ".join(found_metrics)})',
                'fixable': False
            })
        
        # Check for specific targets
        has_targets = bool(re.search(r'\d+\s*(ms|seconds?|req/s|rps)', perf_tests, re.IGNORECASE))
        
        if not has_targets:
            self.issues.append({
                'type': 'warning',
                'section': 'performance_tests',
                'message': 'No specific performance targets defined',
                'fixable': False
            })
    
    def validate_security_tests(self) -> None:
        """Validate security tests section"""
        if 'security_tests' not in self.test_data:
            return
        
        sec_tests = str(self.test_data['security_tests'])
        
        # Check for security test types
        sec_types = ['authentication', 'authorization', 'injection', 'xss', 'csrf', 'encryption', 'access control']
        found_types = [t for t in sec_types if t in sec_tests.lower()]
        
        if len(found_types) < 2:
            self.issues.append({
                'type': 'info',
                'section': 'security_tests',
                'message': f'Limited security test coverage (found: {", ".join(found_types)})',
                'fixable': False
            })
    
    def validate_naming(self) -> None:
        """Validate naming conventions"""
        path_pattern = r'`([^`]+\.(ts|js|py|java|go|rs|md|json|yaml|yml))`'
        
        for section, content in self.test_data.items():
            if not isinstance(content, str):
                continue
            
            paths = re.findall(path_pattern, content)
            for path, ext in paths:
                filename = Path(path).name
                stem = filename.rsplit('.', 1)[0]
                
                if not self._is_kebab_case(stem):
                    self.issues.append({
                        'type': 'warning',
                        'section': section,
                        'path': path,
                        'message': f'File path not in kebab-case: {path}',
                        'fixable': True,
                        'fix': 'convert_kebab_case'
                    })
    
    def _is_kebab_case(self, name: str) -> bool:
        """Check if name is in kebab-case"""
        # Allow test file patterns like test-name.test.ts
        if '.test' in name or '.spec' in name:
            name = name.replace('.test', '').replace('.spec', '')
        return bool(re.match(r'^[a-z0-9]+(-[a-z0-9]+)*$', name))
    
    def auto_fix(self) -> None:
        """Apply automatic fixes"""
        for issue in self.issues:
            if not issue.get('fixable'):
                continue
            
            fix_type = issue.get('fix')
            
            if fix_type == 'add_section':
                section = issue.get('section')
                if section and section not in self.test_data:
                    self.test_data[section] = f'[TODO: Add {section} section]'
                    self.fixes_applied.append(f'Added section: {section}')
            
            elif fix_type == 'add_placeholder':
                section = issue.get('section')
                if section and not str(self.test_data.get(section, '')).strip():
                    self.test_data[section] = f'[TODO: Complete {section} section]'
                    self.fixes_applied.append(f'Added placeholder for: {section}')
    
    def save_tests(self) -> None:
        """Save fixed test spec"""
        if self.test_file.suffix == '.json':
            with open(self.test_file, 'w', encoding='utf-8') as f:
                json.dump(self.test_data, f, indent=2, ensure_ascii=False)
        elif self.test_file.suffix == '.md':
            self._save_markdown()
    
    def _save_markdown(self) -> None:
        """Save test spec as markdown"""
        lines = ['# Test Specification\n']
        
        for section in self.REQUIRED_SECTIONS + self.RECOMMENDED_SECTIONS:
            if section in self.test_data:
                title = section.replace('_', ' ').title()
                lines.append(f'## {title}\n')
                lines.append(f'{self.test_data[section]}\n')
        
        for section, content in self.test_data.items():
            if section not in self.REQUIRED_SECTIONS + self.RECOMMENDED_SECTIONS:
                title = section.replace('_', ' ').title()
                lines.append(f'## {title}\n')
                lines.append(f'{content}\n')
        
        with open(self.test_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
    
    def generate_report(self) -> str:
        """Generate validation report"""
        lines = ['# Generate Tests Validation Report\n', f'**File:** `{self.test_file}`\n']
        
        errors = [i for i in self.issues if i['type'] == 'error']
        warnings = [i for i in self.issues if i['type'] == 'warning']
        infos = [i for i in self.issues if i['type'] == 'info']
        
        lines.append(f'## Summary\n')
        lines.append(f'- **Errors:** {len(errors)}')
        lines.append(f'- **Warnings:** {len(warnings)}')
        lines.append(f'- **Info:** {len(infos)}')
        lines.append(f'- **Fixes Applied:** {len(self.fixes_applied)}\n')
        
        if errors:
            lines.append(f'## Errors\n')
            for issue in errors:
                lines.append(f'- {issue["message"]}')
            lines.append('')
        
        if warnings:
            lines.append(f'## Warnings\n')
            for issue in warnings:
                lines.append(f'- {issue["message"]}')
            lines.append('')
        
        if infos:
            lines.append(f'## Recommendations\n')
            for issue in infos:
                lines.append(f'- {issue["message"]}')
            lines.append('')
        
        if self.fixes_applied:
            lines.append(f'## Fixes Applied\n')
            for fix in self.fixes_applied:
                lines.append(f'- {fix}')
            lines.append('')
        
        return '\n'.join(lines)
    
    def validate(self, apply_fixes: bool = False) -> Tuple[bool, str]:
        """Run full validation"""
        if not self.load_tests():
            return False, self.generate_report()
        
        self.validate_structure()
        self.validate_test_strategy()
        self.validate_test_cases()
        self.validate_test_data()
        self.validate_acceptance_criteria()
        self.validate_edge_cases()
        self.validate_performance_tests()
        self.validate_security_tests()
        self.validate_naming()
        
        if apply_fixes:
            self.auto_fix()
            if self.fixes_applied:
                self.save_tests()
        
        report = self.generate_report()
        errors = [i for i in self.issues if i['type'] == 'error']
        success = len(errors) == 0
        
        return success, report


def main():
    """CLI interface"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Validate generate_tests workflow output')
    parser.add_argument('test_file', help='Path to test specification file')
    parser.add_argument('--repo-root', help='Repository root directory')
    parser.add_argument('--apply', action='store_true', help='Apply automatic fixes')
    parser.add_argument('--output', help='Output report file')
    
    args = parser.parse_args()
    
    validator = GenerateTestsValidator(args.test_file, args.repo_root)
    success, report = validator.validate(apply_fixes=args.apply)
    
    print(report)
    
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report)
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
