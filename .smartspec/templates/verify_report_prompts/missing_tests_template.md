# Test Generation Prompt: Missing Tests

**Category:** Missing Tests  
**Priority:** {{priority}}  
**Generated:** {{timestamp}}  
**Report:** {{report_path}}

---

## Overview

The following tasks have implementation files but no tests. This prompt provides detailed instructions for creating comprehensive tests.

**Tasks in this category:** {{task_count}}

---

{{#each tasks}}
## Task {{task_number}}: {{task_id}} - {{title}}

### Problem
Implementation exists but no test file found.

### Existing Implementation
**File:** `{{code_path}}`  
{{#if code_symbol}}
**Symbol:** `{{code_symbol}}` âœ… (found)
{{/if}}

### Test File to Create
**Path:** `{{test_path}}`

{{#if test_symbol}}
**Required Test:** `{{test_symbol}}`
{{/if}}

{{#if test_contains}}
**Required Content:** `{{test_contains}}`
{{/if}}

### Test Template

```python
import pytest
{{#if code_path}}
from {{code_module}} import {{code_symbol}}
{{/if}}

{{#if test_symbol}}
def {{test_symbol}}():
    """Test {{title}} - basic functionality"""
    # Arrange
    {{#if code_symbol}}
    instance = {{code_symbol}}()
    {{/if}}
    
    # Act
    # TODO: Call method/function
    
    # Assert
    # TODO: Verify results
    pass
{{/if}}

def test_{{task_id_lower}}_edge_cases():
    """Test {{title}} - edge cases"""
    # TODO: Test edge cases
    pass

def test_{{task_id_lower}}_error_handling():
    """Test {{title}} - error handling"""
    # TODO: Test error conditions
    pass
```

### Recommended Test Cases

Based on the implementation, consider testing:

1. **Basic Functionality**
   - Happy path scenarios
   - Normal input/output
   - Expected behavior

2. **Edge Cases**
   - Empty inputs
   - Null/None values
   - Boundary conditions
   - Large inputs

3. **Error Handling**
   - Invalid inputs
   - Exceptions
   - Error messages
   - Recovery behavior

4. **Integration**
   - Dependencies
   - External calls
   - State management

### Implementation Steps

1. **Create test file:**
   ```bash
   touch {{test_path}}
   ```

2. **Add imports:**
   - Import pytest
   - Import implementation
   - Import fixtures (if needed)

3. **Write basic tests:**
   - Test main functionality
   - Use AAA pattern (Arrange, Act, Assert)

4. **Add edge case tests:**
   - Test boundaries
   - Test empty/null cases

5. **Add error tests:**
   - Test exceptions
   - Test invalid inputs

6. **Run tests:**
   ```bash
   pytest {{test_path}} -v
   ```

### Suggestions from Report

{{#each suggestions}}
- {{this}}
{{/each}}

### Verification

After implementation, verify with:
```bash
# Run tests
pytest {{test_path}} -v

# Verify task
/smartspec_verify_tasks_progress_strict {{tasks_path}}
```

**Expected result:** `{{task_id}}` verified âœ…

---

{{/each}}

## Summary

**Total tasks:** {{task_count}}  
**Priority:** {{priority}}  
**Category:** Missing Tests

### Test Coverage Goals

- âœ… All public methods/functions tested
- âœ… Edge cases covered
- âœ… Error handling verified
- âœ… Integration points tested

### Next Steps

1. Review each task above
2. Create test files in order
3. Run tests after each creation
4. Verify all tasks pass

### Verification Command

```bash
# Run all tests
pytest {{test_dir}} -v

# Verify all tasks
/smartspec_verify_tasks_progress_strict {{tasks_path}} --json

# Expected: {{task_count}} tasks verified
```

### What's Next?

After adding tests:

1. **Re-run verification** to check if there are other issues
2. **Generate new prompts** for remaining issues
3. **Execute prompts** (batch or manual)

```bash
# Step 1: Verify again
/smartspec_verify_tasks_progress_strict {{tasks_path}} \
  --out .spec/reports/verify-tasks-progress/latest \
  --json

# Step 2: Generate prompts for remaining issues
/smartspec_report_implement_prompter \
  --verify-report .spec/reports/verify-tasks-progress/latest/summary.json \
  --tasks {{tasks_path}} \
  --out .spec/prompts/latest

# Step 3: Check how many prompts generated
cat .spec/prompts/latest/README.md

# Step 4: Execute (choose based on count)
# - If 1-4 tasks: Manual execution (read prompts one by one)
# - If 5+ tasks: Batch execution (recommended)

python3 .smartspec/scripts/execute_prompts_batch.py \
  --prompts-dir .spec/prompts/latest/ \
  --tasks {{tasks_path}} \
  --checkpoint
```

ðŸ“– **See:** `.smartspec/AFTER_PROMPT_GENERATION_GUIDE.md` for complete workflow

---

**Generated by:** smartspec_report_implement_prompter v7.1.0  
**Template:** missing_tests_template.md  
**Date:** {{timestamp}}
