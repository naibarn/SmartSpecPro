# Python Bridge Specification

**Version:** 1.0  
**Date:** December 29, 2025  
**Status:** Design Phase

---

## ğŸ“‹ Overview

Python Bridge à¹€à¸›à¹‡à¸™à¸Šà¸±à¹‰à¸™ integration layer à¸—à¸µà¹ˆà¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡:
- **Tauri Desktop App** (Rust + React)
- **Kilo Code CLI** (Python)

à¸—à¸³à¹ƒà¸«à¹‰ Desktop App à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ Kilo Code CLI workflows à¹„à¸”à¹‰à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹à¸à¹‰à¹„à¸‚ CLI code

---

## ğŸ¯ Goals

### Primary Goals
1. âœ… à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ Kilo Code CLI workflows à¸ˆà¸²à¸ Tauri
2. âœ… à¸£à¸±à¸š output real-time (stdout/stderr)
3. âœ… à¸ˆà¸±à¸”à¸à¸²à¸£ process lifecycle (start/stop/pause)
4. âœ… Handle errors gracefully
5. âœ… Support multiple concurrent workflows

### Non-Goals
- âŒ à¹„à¸¡à¹ˆà¹à¸à¹‰à¹„à¸‚ Kilo Code CLI source code
- âŒ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ fork à¸«à¸£à¸·à¸­ vendor CLI
- âŒ à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ network (local only)

---

## ğŸ—ï¸ Architecture

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tauri Desktop App                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   React    â”‚ â—„â”€IPCâ”€â”€â–ºâ”‚     Rust     â”‚                   â”‚
â”‚  â”‚  Frontend  â”‚         â”‚   Backend    â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ spawn process
                                  â”‚ stdin/stdout/stderr
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Python Bridge Script   â”‚
                    â”‚   (bridge.py)            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ import & call
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Kilo Code CLI         â”‚
                    â”‚  (.smartspec/ss_autopilot)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Components

### 1. Rust Process Manager (Tauri Backend)

**Location:** `src-tauri/src/python_bridge.rs`

**Responsibilities:**
- Spawn Python processes
- Manage process lifecycle
- Stream stdout/stderr
- Handle process termination
- Queue management

**Key Functions:**
```rust
pub struct PythonBridge {
    python_path: PathBuf,
    bridge_script: PathBuf,
    processes: HashMap<String, Child>,
}

impl PythonBridge {
    // Spawn new workflow process
    pub fn spawn_workflow(&mut self, workflow_id: &str, args: WorkflowArgs) 
        -> Result<ProcessHandle>;
    
    // Get real-time output
    pub fn stream_output(&self, workflow_id: &str) 
        -> Result<Receiver<OutputLine>>;
    
    // Stop workflow
    pub fn stop_workflow(&mut self, workflow_id: &str) 
        -> Result<()>;
    
    // Get process status
    pub fn get_status(&self, workflow_id: &str) 
        -> Result<ProcessStatus>;
}
```

---

### 2. Python Bridge Script

**Location:** `src-tauri/python/bridge.py`

**Responsibilities:**
- CLI entry point for Rust
- Parse command-line arguments
- Import and call Kilo Code CLI
- Format output as JSON
- Handle exceptions

**Interface:**
```python
# Command-line interface
python bridge.py <command> [options]

# Commands:
# - run-workflow: Execute a workflow
# - list-workflows: List available workflows
# - validate-spec: Validate a spec file
# - get-status: Get workflow status
```

**Example Usage:**
```bash
# Run workflow
python bridge.py run-workflow \
  --workflow-id "wf_001" \
  --workflow-name "smartspec_generate_spec" \
  --spec-id "spec-core-001-auth" \
  --output-format "json-stream"

# List workflows
python bridge.py list-workflows \
  --output-format "json"

# Validate spec
python bridge.py validate-spec \
  --spec-path "specs/spec-core-001-auth/spec.md" \
  --output-format "json"
```

---

### 3. Communication Protocol

#### Input (Rust â†’ Python)

**Method:** Command-line arguments + stdin

**Format:**
```json
{
  "command": "run-workflow",
  "workflow_id": "wf_001",
  "workflow_name": "smartspec_generate_spec",
  "args": {
    "spec_id": "spec-core-001-auth",
    "category": "core",
    "mode": "auto",
    "platform": "kilo"
  },
  "config": {
    "output_format": "json-stream",
    "log_level": "info"
  }
}
```

---

#### Output (Python â†’ Rust)

**Method:** stdout (JSON Lines format)

**Format:**
```jsonl
{"type":"started","workflow_id":"wf_001","timestamp":"2025-12-29T10:00:00Z"}
{"type":"log","level":"info","message":"Loading workflow...","timestamp":"2025-12-29T10:00:01Z"}
{"type":"progress","step":"generate_spec","progress":0.25,"message":"Generating specification..."}
{"type":"log","level":"info","message":"Spec generated successfully"}
{"type":"progress","step":"generate_spec","progress":1.0,"message":"Complete"}
{"type":"completed","workflow_id":"wf_001","result":{"success":true},"timestamp":"2025-12-29T10:05:00Z"}
```

**Message Types:**
- `started` - Workflow started
- `log` - Log message (info/warning/error)
- `progress` - Progress update (0.0-1.0)
- `output` - Command output
- `error` - Error occurred
- `completed` - Workflow completed
- `failed` - Workflow failed

---

#### Error Output (Python â†’ Rust)

**Method:** stderr (JSON Lines format)

**Format:**
```jsonl
{"type":"error","code":"WORKFLOW_NOT_FOUND","message":"Workflow 'invalid' not found","timestamp":"2025-12-29T10:00:00Z"}
{"type":"error","code":"SPEC_INVALID","message":"Spec validation failed: missing required field 'title'","details":{"field":"title","line":10}}
```

---

## ğŸ’» Implementation Details

### Bridge Script Structure

```python
#!/usr/bin/env python3
"""
Python Bridge for Kilo Code CLI

This script acts as a bridge between Tauri Desktop App and Kilo Code CLI.
It provides a JSON-based interface for executing workflows and getting results.
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

# Import Kilo Code CLI modules
sys.path.insert(0, str(Path(__file__).parent.parent.parent / ".smartspec"))
from ss_autopilot.cli_enhanced import run_workflow, list_workflows
from ss_autopilot.workflow_catalog import WorkflowCatalog

class JsonStreamLogger:
    """Logger that outputs JSON Lines to stdout"""
    
    def __init__(self, workflow_id: str):
        self.workflow_id = workflow_id
    
    def log(self, level: str, message: str, **kwargs):
        """Log a message"""
        data = {
            "type": "log",
            "workflow_id": self.workflow_id,
            "level": level,
            "message": message,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            **kwargs
        }
        print(json.dumps(data), flush=True)
    
    def progress(self, step: str, progress: float, message: str):
        """Report progress"""
        data = {
            "type": "progress",
            "workflow_id": self.workflow_id,
            "step": step,
            "progress": progress,
            "message": message,
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }
        print(json.dumps(data), flush=True)
    
    def error(self, code: str, message: str, **kwargs):
        """Log an error"""
        data = {
            "type": "error",
            "workflow_id": self.workflow_id,
            "code": code,
            "message": message,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            **kwargs
        }
        print(json.dumps(data), file=sys.stderr, flush=True)


class WorkflowRunner:
    """Execute Kilo Code CLI workflows"""
    
    def __init__(self, workflow_id: str):
        self.workflow_id = workflow_id
        self.logger = JsonStreamLogger(workflow_id)
        self.catalog = WorkflowCatalog()
    
    def run(self, workflow_name: str, args: Dict[str, Any]) -> Dict[str, Any]:
        """Run a workflow"""
        try:
            # Log start
            self.logger.log("info", f"Starting workflow: {workflow_name}")
            print(json.dumps({
                "type": "started",
                "workflow_id": self.workflow_id,
                "workflow_name": workflow_name,
                "timestamp": datetime.utcnow().isoformat() + "Z"
            }), flush=True)
            
            # Get workflow
            workflow = self.catalog.get_workflow(workflow_name)
            if not workflow:
                raise ValueError(f"Workflow '{workflow_name}' not found")
            
            # Execute workflow
            self.logger.progress("execute", 0.0, "Initializing...")
            result = self._execute_workflow(workflow, args)
            self.logger.progress("execute", 1.0, "Complete")
            
            # Log completion
            self.logger.log("info", "Workflow completed successfully")
            print(json.dumps({
                "type": "completed",
                "workflow_id": self.workflow_id,
                "result": result,
                "timestamp": datetime.utcnow().isoformat() + "Z"
            }), flush=True)
            
            return result
            
        except Exception as e:
            # Log error
            self.logger.error("WORKFLOW_FAILED", str(e))
            print(json.dumps({
                "type": "failed",
                "workflow_id": self.workflow_id,
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat() + "Z"
            }), flush=True)
            raise
    
    def _execute_workflow(self, workflow: Dict[str, Any], args: Dict[str, Any]) -> Dict[str, Any]:
        """Execute workflow steps"""
        # This is where we call the actual Kilo Code CLI functions
        # For now, this is a placeholder
        
        spec_id = args.get("spec_id")
        category = args.get("category", "core")
        mode = args.get("mode", "auto")
        platform = args.get("platform", "kilo")
        
        # Import and call CLI function
        from ss_autopilot.cli_enhanced import run_autopilot
        
        result = run_autopilot(
            spec_id=spec_id,
            category=category,
            mode=mode,
            platform=platform
        )
        
        return {
            "success": True,
            "spec_id": spec_id,
            "output": result
        }


def cmd_run_workflow(args):
    """Run a workflow"""
    runner = WorkflowRunner(args.workflow_id)
    
    workflow_args = {
        "spec_id": args.spec_id,
        "category": args.category,
        "mode": args.mode,
        "platform": args.platform
    }
    
    result = runner.run(args.workflow_name, workflow_args)
    return 0 if result.get("success") else 1


def cmd_list_workflows(args):
    """List available workflows"""
    catalog = WorkflowCatalog()
    workflows = catalog.list_workflows()
    
    output = {
        "type": "workflows_list",
        "workflows": workflows,
        "count": len(workflows),
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }
    
    print(json.dumps(output), flush=True)
    return 0


def cmd_validate_spec(args):
    """Validate a spec file"""
    spec_path = Path(args.spec_path)
    
    if not spec_path.exists():
        error = {
            "type": "error",
            "code": "SPEC_NOT_FOUND",
            "message": f"Spec file not found: {spec_path}",
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }
        print(json.dumps(error), file=sys.stderr, flush=True)
        return 1
    
    # Validate spec (placeholder)
    result = {
        "type": "validation_result",
        "valid": True,
        "spec_path": str(spec_path),
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }
    
    print(json.dumps(result), flush=True)
    return 0


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description="Python Bridge for Kilo Code CLI")
    subparsers = parser.add_subparsers(dest="command", required=True)
    
    # run-workflow command
    run_parser = subparsers.add_parser("run-workflow", help="Run a workflow")
    run_parser.add_argument("--workflow-id", required=True, help="Unique workflow ID")
    run_parser.add_argument("--workflow-name", required=True, help="Workflow name")
    run_parser.add_argument("--spec-id", required=True, help="Spec ID")
    run_parser.add_argument("--category", default="core", help="Spec category")
    run_parser.add_argument("--mode", default="auto", help="Execution mode")
    run_parser.add_argument("--platform", default="kilo", help="Platform")
    run_parser.set_defaults(func=cmd_run_workflow)
    
    # list-workflows command
    list_parser = subparsers.add_parser("list-workflows", help="List available workflows")
    list_parser.set_defaults(func=cmd_list_workflows)
    
    # validate-spec command
    validate_parser = subparsers.add_parser("validate-spec", help="Validate a spec file")
    validate_parser.add_argument("--spec-path", required=True, help="Path to spec file")
    validate_parser.set_defaults(func=cmd_validate_spec)
    
    args = parser.parse_args()
    
    try:
        return args.func(args)
    except Exception as e:
        error = {
            "type": "error",
            "code": "UNKNOWN_ERROR",
            "message": str(e),
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }
        print(json.dumps(error), file=sys.stderr, flush=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

---

### Rust Process Manager

```rust
// src-tauri/src/python_bridge.rs

use std::collections::HashMap;
use std::path::PathBuf;
use std::process::{Child, Command, Stdio};
use std::sync::{Arc, Mutex};
use tokio::io::{AsyncBufReadExt, BufReader};
use tokio::process::Command as TokioCommand;
use tokio::sync::mpsc;
use serde::{Deserialize, Serialize};
use anyhow::{Result, Context};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowArgs {
    pub spec_id: String,
    pub category: String,
    pub mode: String,
    pub platform: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum OutputMessage {
    Started {
        workflow_id: String,
        workflow_name: String,
        timestamp: String,
    },
    Log {
        workflow_id: String,
        level: String,
        message: String,
        timestamp: String,
    },
    Progress {
        workflow_id: String,
        step: String,
        progress: f64,
        message: String,
        timestamp: String,
    },
    Output {
        workflow_id: String,
        content: String,
        timestamp: String,
    },
    Error {
        workflow_id: String,
        code: String,
        message: String,
        timestamp: String,
    },
    Completed {
        workflow_id: String,
        result: serde_json::Value,
        timestamp: String,
    },
    Failed {
        workflow_id: String,
        error: String,
        timestamp: String,
    },
}

pub struct ProcessHandle {
    pub workflow_id: String,
    pub child: Child,
    pub output_rx: mpsc::Receiver<OutputMessage>,
}

pub struct PythonBridge {
    python_path: PathBuf,
    bridge_script: PathBuf,
    processes: Arc<Mutex<HashMap<String, ProcessHandle>>>,
}

impl PythonBridge {
    pub fn new() -> Result<Self> {
        // Find Python executable
        let python_path = which::which("python3")
            .or_else(|_| which::which("python"))
            .context("Python not found in PATH")?;
        
        // Find bridge script
        let bridge_script = PathBuf::from("src-tauri/python/bridge.py");
        if !bridge_script.exists() {
            anyhow::bail!("Bridge script not found: {:?}", bridge_script);
        }
        
        Ok(Self {
            python_path,
            bridge_script,
            processes: Arc::new(Mutex::new(HashMap::new())),
        })
    }
    
    pub async fn spawn_workflow(
        &self,
        workflow_id: String,
        workflow_name: String,
        args: WorkflowArgs,
    ) -> Result<()> {
        // Build command
        let mut cmd = TokioCommand::new(&self.python_path);
        cmd.arg(&self.bridge_script)
            .arg("run-workflow")
            .arg("--workflow-id").arg(&workflow_id)
            .arg("--workflow-name").arg(&workflow_name)
            .arg("--spec-id").arg(&args.spec_id)
            .arg("--category").arg(&args.category)
            .arg("--mode").arg(&args.mode)
            .arg("--platform").arg(&args.platform)
            .stdout(Stdio::piped())
            .stderr(Stdio::piped());
        
        // Spawn process
        let mut child = cmd.spawn()
            .context("Failed to spawn Python process")?;
        
        // Create channel for output
        let (tx, rx) = mpsc::channel(100);
        
        // Spawn task to read stdout
        let stdout = child.stdout.take().unwrap();
        let workflow_id_clone = workflow_id.clone();
        tokio::spawn(async move {
            let reader = BufReader::new(stdout);
            let mut lines = reader.lines();
            
            while let Ok(Some(line)) = lines.next_line().await {
                if let Ok(msg) = serde_json::from_str::<OutputMessage>(&line) {
                    let _ = tx.send(msg).await;
                }
            }
        });
        
        // Store process handle
        let handle = ProcessHandle {
            workflow_id: workflow_id.clone(),
            child,
            output_rx: rx,
        };
        
        self.processes.lock().unwrap().insert(workflow_id, handle);
        
        Ok(())
    }
    
    pub fn get_output(&self, workflow_id: &str) -> Result<Option<OutputMessage>> {
        let mut processes = self.processes.lock().unwrap();
        
        if let Some(handle) = processes.get_mut(workflow_id) {
            match handle.output_rx.try_recv() {
                Ok(msg) => Ok(Some(msg)),
                Err(mpsc::error::TryRecvError::Empty) => Ok(None),
                Err(mpsc::error::TryRecvError::Disconnected) => {
                    anyhow::bail!("Process output channel disconnected")
                }
            }
        } else {
            anyhow::bail!("Workflow not found: {}", workflow_id)
        }
    }
    
    pub fn stop_workflow(&self, workflow_id: &str) -> Result<()> {
        let mut processes = self.processes.lock().unwrap();
        
        if let Some(mut handle) = processes.remove(workflow_id) {
            handle.child.kill()
                .context("Failed to kill process")?;
            Ok(())
        } else {
            anyhow::bail!("Workflow not found: {}", workflow_id)
        }
    }
    
    pub fn get_status(&self, workflow_id: &str) -> Result<String> {
        let processes = self.processes.lock().unwrap();
        
        if let Some(handle) = processes.get(workflow_id) {
            match handle.child.try_wait() {
                Ok(Some(status)) => Ok(format!("Exited: {}", status)),
                Ok(None) => Ok("Running".to_string()),
                Err(e) => Ok(format!("Error: {}", e)),
            }
        } else {
            Ok("Not found".to_string())
        }
    }
}
```

---

### Tauri Commands

```rust
// src-tauri/src/main.rs

use tauri::State;
use std::sync::Mutex;

struct AppState {
    python_bridge: Mutex<PythonBridge>,
}

#[tauri::command]
async fn run_workflow(
    state: State<'_, AppState>,
    workflow_id: String,
    workflow_name: String,
    args: WorkflowArgs,
) -> Result<(), String> {
    let bridge = state.python_bridge.lock().unwrap();
    
    bridge.spawn_workflow(workflow_id, workflow_name, args)
        .await
        .map_err(|e| e.to_string())
}

#[tauri::command]
fn get_workflow_output(
    state: State<'_, AppState>,
    workflow_id: String,
) -> Result<Option<OutputMessage>, String> {
    let bridge = state.python_bridge.lock().unwrap();
    
    bridge.get_output(&workflow_id)
        .map_err(|e| e.to_string())
}

#[tauri::command]
fn stop_workflow(
    state: State<'_, AppState>,
    workflow_id: String,
) -> Result<(), String> {
    let bridge = state.python_bridge.lock().unwrap();
    
    bridge.stop_workflow(&workflow_id)
        .map_err(|e| e.to_string())
}

#[tauri::command]
fn get_workflow_status(
    state: State<'_, AppState>,
    workflow_id: String,
) -> Result<String, String> {
    let bridge = state.python_bridge.lock().unwrap();
    
    bridge.get_status(&workflow_id)
        .map_err(|e| e.to_string())
}

fn main() {
    let python_bridge = PythonBridge::new().expect("Failed to initialize Python bridge");
    
    tauri::Builder::default()
        .manage(AppState {
            python_bridge: Mutex::new(python_bridge),
        })
        .invoke_handler(tauri::generate_handler![
            run_workflow,
            get_workflow_output,
            stop_workflow,
            get_workflow_status,
        ])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
```

---

### React Frontend Usage

```typescript
// src/hooks/useWorkflow.ts

import { invoke } from '@tauri-apps/api/core';
import { useState, useEffect, useCallback } from 'react';

interface WorkflowArgs {
  specId: string;
  category: string;
  mode: string;
  platform: string;
}

interface OutputMessage {
  type: string;
  workflow_id?: string;
  level?: string;
  message?: string;
  progress?: number;
  timestamp?: string;
  [key: string]: any;
}

export function useWorkflow(workflowId: string) {
  const [status, setStatus] = useState<string>('idle');
  const [output, setOutput] = useState<OutputMessage[]>([]);
  const [error, setError] = useState<string | null>(null);
  
  // Poll for output
  useEffect(() => {
    if (status !== 'running') return;
    
    const interval = setInterval(async () => {
      try {
        const msg = await invoke<OutputMessage | null>('get_workflow_output', {
          workflowId,
        });
        
        if (msg) {
          setOutput(prev => [...prev, msg]);
          
          if (msg.type === 'completed') {
            setStatus('completed');
          } else if (msg.type === 'failed') {
            setStatus('failed');
            setError(msg.error || 'Unknown error');
          }
        }
      } catch (err) {
        console.error('Failed to get output:', err);
      }
    }, 100); // Poll every 100ms
    
    return () => clearInterval(interval);
  }, [workflowId, status]);
  
  const start = useCallback(async (workflowName: string, args: WorkflowArgs) => {
    try {
      setStatus('running');
      setOutput([]);
      setError(null);
      
      await invoke('run_workflow', {
        workflowId,
        workflowName,
        args,
      });
    } catch (err) {
      setStatus('failed');
      setError(String(err));
    }
  }, [workflowId]);
  
  const stop = useCallback(async () => {
    try {
      await invoke('stop_workflow', { workflowId });
      setStatus('stopped');
    } catch (err) {
      console.error('Failed to stop workflow:', err);
    }
  }, [workflowId]);
  
  return {
    status,
    output,
    error,
    start,
    stop,
  };
}
```

**Usage in Component:**
```typescript
// src/components/WorkflowRunner.tsx

import { useWorkflow } from '../hooks/useWorkflow';

export function WorkflowRunner() {
  const { status, output, error, start, stop } = useWorkflow('wf_001');
  
  const handleStart = () => {
    start('smartspec_generate_spec', {
      specId: 'spec-core-001-auth',
      category: 'core',
      mode: 'auto',
      platform: 'kilo',
    });
  };
  
  return (
    <div>
      <button onClick={handleStart} disabled={status === 'running'}>
        Start Workflow
      </button>
      <button onClick={stop} disabled={status !== 'running'}>
        Stop
      </button>
      
      <div>Status: {status}</div>
      
      {error && <div>Error: {error}</div>}
      
      <div>
        {output.map((msg, i) => (
          <div key={i}>
            {msg.type === 'log' && <div>{msg.message}</div>}
            {msg.type === 'progress' && (
              <div>
                {msg.step}: {(msg.progress * 100).toFixed(0)}%
              </div>
            )}
          </div>
        ))}
      </div>
    </div>
  );
}
```

---

## ğŸ”’ Security Considerations

### 1. Process Isolation
- âœ… Each workflow runs in separate process
- âœ… No shared memory between processes
- âœ… Process killed on app exit

### 2. Input Validation
- âœ… Validate all arguments before spawning
- âœ… Sanitize file paths
- âœ… Limit workflow names to whitelist

### 3. Resource Limits
- âœ… Limit concurrent workflows (e.g., 10 max)
- âœ… Timeout for long-running workflows
- âœ… Memory limits (via OS)

### 4. Error Handling
- âœ… Catch all Python exceptions
- âœ… Log errors to stderr
- âœ… Graceful degradation

---

## ğŸ“Š Performance

### Expected Performance

| Metric | Value |
|--------|-------|
| **Process Spawn Time** | < 500ms |
| **Output Latency** | < 100ms |
| **Memory per Process** | 50-100 MB |
| **Max Concurrent Workflows** | 10 |
| **CPU Usage** | 1-10% per workflow |

### Optimization Strategies

1. **Process Pooling** - Reuse Python processes
2. **Output Buffering** - Batch output messages
3. **Lazy Loading** - Load CLI modules on demand
4. **Caching** - Cache workflow metadata

---

## ğŸ§ª Testing Strategy

### Unit Tests

**Rust:**
- Test process spawning
- Test output parsing
- Test error handling
- Test process lifecycle

**Python:**
- Test command parsing
- Test workflow execution
- Test JSON output format
- Test error cases

### Integration Tests

- Test full workflow execution
- Test real-time output streaming
- Test process termination
- Test concurrent workflows
- Test error recovery

### E2E Tests

- Test from React UI
- Test multiple workflows
- Test long-running workflows
- Test network interruption

---

## ğŸ“ Future Enhancements

### Phase 2+

1. **Process Pooling** - Reuse Python processes for faster startup
2. **Binary Protocol** - Use msgpack instead of JSON for efficiency
3. **WebSocket** - Alternative to polling for real-time updates
4. **Workflow Queue** - Queue workflows when limit reached
5. **Progress Estimation** - Estimate time remaining
6. **Cancellation** - Graceful cancellation with cleanup
7. **Checkpointing** - Resume workflows after crash
8. **Distributed** - Run workflows on remote machines

---

## âœ… Success Criteria

Phase 1 is complete when:

- âœ… Can spawn Python process from Rust
- âœ… Can execute Kilo Code CLI workflows
- âœ… Can receive real-time output
- âœ… Can stop workflows gracefully
- âœ… Can handle errors properly
- âœ… Can run multiple workflows concurrently
- âœ… Tests passing (80%+ coverage)
- âœ… Documentation complete

---

## ğŸ“š References

### Technologies

- **Rust:** https://www.rust-lang.org/
- **Tokio:** https://tokio.rs/
- **Tauri:** https://tauri.app/
- **Python:** https://www.python.org/
- **JSON Lines:** https://jsonlines.org/

### Similar Projects

- **Tauri Sidecar:** https://tauri.app/v1/guides/building/sidecar/
- **Electron IPC:** https://www.electronjs.org/docs/latest/tutorial/ipc
- **PyO3:** https://pyo3.rs/ (alternative: embed Python in Rust)

---

## âœ¨ Summary

Python Bridge provides:

1. âœ… **Clean Interface** - JSON-based, language-agnostic
2. âœ… **Real-time Output** - Stream stdout/stderr
3. âœ… **Process Management** - Start/stop/monitor
4. âœ… **Error Handling** - Graceful error recovery
5. âœ… **Concurrent Execution** - Multiple workflows
6. âœ… **No Code Changes** - Works with existing CLI
7. âœ… **Testable** - Unit, integration, E2E tests
8. âœ… **Performant** - < 500ms spawn, < 100ms latency

**Ready for Phase 1 implementation!** ğŸš€

---

**Version:** 1.0  
**Author:** Manus AI  
**Project:** Kilo Code Desktop App
