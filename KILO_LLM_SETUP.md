# ðŸš€ Kilo CLI + LLM Integration Setup Guide

à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹à¸¥à¸° config à¹ƒà¸«à¹‰ Kilo CLI à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š LLM à¸œà¹ˆà¸²à¸™ Python Backend Proxy

---

## âœ… à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰ implement à¹à¸¥à¹‰à¸§

### 1. **LLM Client à¸ªà¸³à¸«à¸£à¸±à¸š Kilo CLI**
- à¹„à¸Ÿà¸¥à¹Œ: `.smartspec/ss_autopilot/llm_client.py`
- à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ:
  - âœ… à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ LLM à¸œà¹ˆà¸²à¸™ Backend OpenAI-compatible endpoint
  - âœ… à¸£à¸­à¸‡à¸£à¸±à¸š error handling (401, 402, 500)
  - âœ… à¹à¸ªà¸”à¸‡ usage statistics
  - âœ… à¸£à¸­à¸‡à¸£à¸±à¸š workflow execution

### 2. **Kilo CLI Integration**
- à¹„à¸Ÿà¸¥à¹Œ: `.smartspec/ss_autopilot/cli_enhanced.py`
- à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ:
  - âœ… à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ LLM à¹€à¸¡à¸·à¹ˆà¸­à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹ƒà¸«à¹‰ input
  - âœ… à¸ªà¹ˆà¸‡ workflow content + user input à¹„à¸›à¸¢à¸±à¸‡ LLM
  - âœ… à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸ˆà¸²à¸ LLM à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢
  - âœ… Error handling à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸à¸à¸£à¸“à¸µ

### 3. **Python Backend Proxy**
- à¹„à¸Ÿà¸¥à¹Œ: `python-backend/app/api/openai_compat.py`
- à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ:
  - âœ… à¸£à¸­à¸‡à¸£à¸±à¸šà¸ªà¸­à¸‡à¹‚à¸«à¸¡à¸”:
    - **Direct Proxy Mode** (USE_WEB_GATEWAY=false) - à¹ƒà¸Šà¹‰ local providers
    - **Web Gateway Mode** (USE_WEB_GATEWAY=true) - à¹ƒà¸Šà¹‰ SmartSpecWeb gateway
  - âœ… OpenAI-compatible format
  - âœ… Multi-provider support (OpenRouter, OpenAI, Anthropic, etc.)

---

## ðŸ“‹ à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£ Setup

### à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 1: à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies

```bash
cd /home/naibarn/projects/SmartSpecPro

# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ requests library à¸ªà¸³à¸«à¸£à¸±à¸š Kilo CLI
pip install requests

# à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ backend dependencies
cd python-backend
pip install -r requirements.txt
```

### à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 2: Setup LLM Provider API Key

à¹€à¸¥à¸·à¸­à¸ **à¸«à¸™à¸¶à¹ˆà¸‡** à¹ƒà¸™à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰:

#### à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸ A: OpenRouter (à¹à¸™à¸°à¸™à¸³ - 420+ models, API key à¹€à¸”à¸µà¸¢à¸§)

1. à¹„à¸›à¸—à¸µà¹ˆ: https://openrouter.ai/keys
2. à¸ªà¸£à¹‰à¸²à¸‡ API key
3. à¹à¸à¹‰à¹„à¸‚ `python-backend/.env`:

```bash
# Option 1: OpenRouter (Recommended)
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENROUTER_SITE_URL=https://smartspec.pro
OPENROUTER_SITE_NAME=SmartSpec Pro
USE_OPENROUTER=true
```

#### à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸ B: OpenAI Direct

```bash
# Option 2: OpenAI
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

#### à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸ C: Anthropic Direct

```bash
# Option 3: Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

#### à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸ D: Kilo Code (à¹à¸™à¸°à¸™à¸³ - OpenRouter-compatible)

```bash
# Option 4: Kilo Code
KILOCODE_API_KEY=kilo_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
KILOCODE_BASE_URL=https://api.kilo.ai/api/openrouter
```

### à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 3: Config Kilo CLI Environment Variables

à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ `.env` à¸—à¸µà¹ˆ root project à¸«à¸£à¸·à¸­ export à¸•à¸±à¸§à¹à¸›à¸£à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰:

```bash
# Backend URL
export SMARTSPEC_BACKEND_URL=http://localhost:8000

# Proxy Token (à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸šà¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡à¹ƒà¸™ python-backend/.env)
export SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026

# Default Model (optional)
export SMARTSPEC_DEFAULT_MODEL=anthropic/claude-3-5-sonnet-20241022
```

à¸«à¸£à¸·à¸­à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ `.env` à¸—à¸µà¹ˆ root:

```bash
cat > .env <<EOF
SMARTSPEC_BACKEND_URL=http://localhost:8000
SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026
SMARTSPEC_DEFAULT_MODEL=anthropic/claude-3-5-sonnet-20241022
EOF
```

### à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 4: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Backend Configuration

à¹à¸à¹‰à¹„à¸‚ `python-backend/.env` à¹ƒà¸«à¹‰à¸¡à¸µà¸„à¹ˆà¸²à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰:

```bash
# Kilo CLI / Desktop App Security
SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026
SMARTSPEC_LOCALHOST_ONLY=false

# LLM Gateway Mode (à¹€à¸¥à¸·à¸­à¸à¹‚à¸«à¸¡à¸”)
# Mode 1: Direct Proxy (à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™)
SMARTSPEC_USE_WEB_GATEWAY=false

# Mode 2: Web Gateway (à¸–à¹‰à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰ SmartSpecWeb)
# SMARTSPEC_USE_WEB_GATEWAY=true
# SMARTSPEC_WEB_GATEWAY_URL=http://localhost:3000/api/v1/llm/openai/chat/completions
# SMARTSPEC_WEB_GATEWAY_TOKEN=your_gateway_token_here
```

### à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 5: Start Python Backend

```bash
cd python-backend
python -m uvicorn app.main:app --reload --port 8000
```

à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² backend à¸—à¸³à¸‡à¸²à¸™:
```bash
curl http://localhost:8000/health
```

### à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 6: à¸—à¸”à¸ªà¸­à¸š LLM Connection

#### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1: à¸—à¸”à¸ªà¸­à¸šà¸œà¹ˆà¸²à¸™ LLM Client à¹‚à¸”à¸¢à¸•à¸£à¸‡

```bash
cd /home/naibarn/projects/SmartSpecPro

# Export environment variables
export SMARTSPEC_BACKEND_URL=http://localhost:8000
export SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026

# Run test
python -m ss_autopilot.llm_client
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
âœ… LLM Client initialized
   Backend URL: http://localhost:8000
   Model: anthropic/claude-3-5-sonnet-20241022
   Has token: True

ðŸ§ª Testing connection with simple message...
âœ… Connection successful!
   Response: Hello from Kilo CLI
   Model: anthropic/claude-3-5-sonnet
   Usage: {'prompt_tokens': 10, 'completion_tokens': 8, 'total_tokens': 18}
```

#### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 2: à¸—à¸”à¸ªà¸­à¸šà¸œà¹ˆà¸²à¸™ Kilo CLI

```bash
cd /home/naibarn/projects/SmartSpecPro

# Export environment variables
export SMARTSPEC_BACKEND_URL=http://localhost:8000
export SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026

# Run workflow with input
python -m ss_autopilot.cli_enhanced /test_hello.md "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š"
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡:**
```
ðŸ” Executing workflow: test_hello

ðŸš€ Executing workflow with LLM...
   - Workflow: test_hello
   - User input: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
   - Platform: kilo

ðŸ¤– Calling LLM with model: anthropic/claude-3-5-sonnet-20241022
ðŸ“ Workflow length: 52 characters
ðŸ’¬ User input: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š...
âœ… LLM responded with 156 characters

================================================================================
ðŸ¤– LLM Response:
================================================================================

à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š! à¸¢à¸´à¸™à¸”à¸µà¸•à¹‰à¸­à¸™à¸£à¸±à¸šà¸ªà¸¹à¹ˆ Kilo CLI

[LLM response content here...]

================================================================================

ðŸ“Š Usage Statistics:
   - Prompt tokens: N/A
   - Completion tokens: N/A
   - Total tokens: 234

âœ… Workflow executed successfully!
```

#### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 3: à¸—à¸”à¸ªà¸­à¸šà¸œà¹ˆà¸²à¸™ Desktop App

1. à¹€à¸›à¸´à¸” Desktop App: http://localhost:1420
2. à¹„à¸›à¸—à¸µà¹ˆà¸«à¸™à¹‰à¸² "Kilo CLI (Compat)"
3. à¹ƒà¸ªà¹ˆ Proxy Token: `dev-token-smartspec-2026`
4. à¹ƒà¸ªà¹ˆ Workspace: `/home/naibarn/projects/SmartSpecPro`
5. à¸à¸” "Refresh workflows"
6. à¸žà¸´à¸¡à¸žà¹Œà¸„à¸³à¸ªà¸±à¹ˆà¸‡: `/test_hello à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š`
7. à¸à¸” "Run"

---

## ðŸ” Flow à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸£à¸°à¸šà¸š

```
Desktop App UI
    â”‚
    â–¼
Python Backend (/api/v1/kilo/run)
    â”‚
    â–¼
Job Manager (subprocess)
    â”‚
    â–¼
Kilo CLI (ss_autopilot.cli_enhanced)
    â”‚
    â”œâ”€ Load workflow.md
    â”‚
    â”œâ”€ Check user input
    â”‚
    â–¼
LLM Client (llm_client.py)
    â”‚
    â–¼
HTTP POST to Backend (/v1/chat/completions)
    â”‚
    â”œâ”€ Check: USE_WEB_GATEWAY?
    â”‚
    â”œâ”€ If FALSE â†’ UnifiedLLMClient
    â”‚   â”‚
    â”‚   â”œâ”€ Check: OPENROUTER_API_KEY?
    â”‚   â”‚   â”œâ”€ Yes â†’ Use OpenRouter
    â”‚   â”‚   â””â”€ No â†’ Use other providers
    â”‚   â”‚
    â”‚   â–¼
    â”‚   OpenRouter / OpenAI / Anthropic / etc.
    â”‚
    â””â”€ If TRUE â†’ SmartSpecWeb Gateway
        â”‚
        â–¼
        Web Gateway â†’ Forge API â†’ LLM Provider
```

---

## âŒ Troubleshooting

### à¸›à¸±à¸à¸«à¸²: "requests library not found"

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
```bash
pip install requests
```

### à¸›à¸±à¸à¸«à¸²: "Failed to connect to backend"

**à¸ªà¸²à¹€à¸«à¸•à¸¸:** Backend à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸£à¸±à¸™

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
```bash
cd python-backend
python -m uvicorn app.main:app --reload --port 8000
```

### à¸›à¸±à¸à¸«à¸²: "Authentication Failed"

**à¸ªà¸²à¹€à¸«à¸•à¸¸:** SMARTSPEC_PROXY_TOKEN à¹„à¸¡à¹ˆà¸•à¸£à¸‡à¸à¸±à¸™

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š `python-backend/.env`:
   ```bash
   SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026
   ```
2. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š environment variable:
   ```bash
   echo $SMARTSPEC_PROXY_TOKEN
   ```
3. à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™à¸„à¹ˆà¸²à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™!

### à¸›à¸±à¸à¸«à¸²: "Gateway Error: SMARTSPEC_WEB_GATEWAY_URL not configured"

**à¸ªà¸²à¹€à¸«à¸•à¸¸:** USE_WEB_GATEWAY=true à¹à¸•à¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ URL

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**

à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸ A: à¸›à¸´à¸” Web Gateway (à¹à¸™à¸°à¸™à¸³)
```bash
# à¹ƒà¸™ python-backend/.env
SMARTSPEC_USE_WEB_GATEWAY=false
```

à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸ B: Setup Web Gateway
```bash
# à¹ƒà¸™ python-backend/.env
SMARTSPEC_USE_WEB_GATEWAY=true
SMARTSPEC_WEB_GATEWAY_URL=http://localhost:3000/api/v1/llm/openai/chat/completions
SMARTSPEC_WEB_GATEWAY_TOKEN=your_token_here
```

### à¸›à¸±à¸à¸«à¸²: "LLM call failed: No API key configured"

**à¸ªà¸²à¹€à¸«à¸•à¸¸:** à¹„à¸¡à¹ˆà¸¡à¸µ LLM provider API key

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
1. à¸•à¸´à¸”à¸•à¸²à¸¡ "à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 2: Setup LLM Provider API Key" à¸”à¹‰à¸²à¸™à¸šà¸™
2. Restart Backend:
   ```bash
   # Ctrl+C à¹à¸¥à¹‰à¸§à¸£à¸±à¸™à¹ƒà¸«à¸¡à¹ˆ
   python -m uvicorn app.main:app --reload --port 8000
   ```

### à¸›à¸±à¸à¸«à¸²: "Insufficient Credits"

**à¸ªà¸²à¹€à¸«à¸•à¸¸:** à¸–à¹‰à¸²à¹ƒà¸Šà¹‰ credit system à¹à¸¥à¸° credits à¸«à¸¡à¸”

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
- à¸ªà¸³à¸«à¸£à¸±à¸š Direct Proxy mode: à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ credit (FREE)
- à¸ªà¸³à¸«à¸£à¸±à¸š Web Gateway mode: à¸•à¹‰à¸­à¸‡ top up credits

---

## ðŸ’¡ Models à¸—à¸µà¹ˆà¹à¸™à¸°à¸™à¸³

### à¸ªà¸³à¸«à¸£à¸±à¸š Code Generation:
- `anthropic/claude-3-5-sonnet-20241022` (Quality)
- `meta-llama/llama-3.1-70b-instruct` (Cost-effective)
- `google/gemini-flash-1.5` (Speed)

### à¸ªà¸³à¸«à¸£à¸±à¸š Analysis:
- `openai/gpt-4o` (Quality)
- `anthropic/claude-3-5-sonnet` (Balanced)

### à¸ªà¸³à¸«à¸£à¸±à¸š Simple Tasks:
- `openai/gpt-4o-mini` (Fast & cheap)
- `google/gemini-flash-1.5` (Speed)

**à¸§à¸´à¸˜à¸µà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ model:**
```bash
export SMARTSPEC_DEFAULT_MODEL=anthropic/claude-3-5-sonnet-20241022
```

à¸«à¸£à¸·à¸­à¸£à¸°à¸šà¸¸à¹ƒà¸™ workflow call:
```python
response = llm_client.chat(
    messages=[...],
    model="openai/gpt-4o"
)
```

---

## ðŸ“Š à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸–à¸²à¸™à¸°à¸£à¸°à¸šà¸š

### 1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Backend
```bash
curl http://localhost:8000/health
```

### 2. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Proxy Token
```bash
curl -H "x-proxy-token: dev-token-smartspec-2026" \
     http://localhost:8000/api/v1/kilo/workflows
```

### 3. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š LLM Endpoint
```bash
curl -X POST http://localhost:8000/v1/chat/completions \
     -H "x-proxy-token: dev-token-smartspec-2026" \
     -H "Content-Type: application/json" \
     -d '{
       "model": "anthropic/claude-3-5-sonnet-20241022",
       "messages": [{"role": "user", "content": "Say hello"}],
       "max_tokens": 50
     }'
```

---

## âœ… Checklist à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£ Setup

- [ ] à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ `requests` library
- [ ] Setup LLM Provider API key (OpenRouter/OpenAI/Anthropic)
- [ ] Config `python-backend/.env`
- [ ] Set environment variables à¸ªà¸³à¸«à¸£à¸±à¸š Kilo CLI
- [ ] Start Python Backend
- [ ] à¸—à¸”à¸ªà¸­à¸š LLM Client
- [ ] à¸—à¸”à¸ªà¸­à¸š Kilo CLI
- [ ] à¸—à¸”à¸ªà¸­à¸šà¸œà¹ˆà¸²à¸™ Desktop App (optional)

---

## ðŸŽ¯ à¸ªà¸£à¸¸à¸›

à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸ setup à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ à¸„à¸¸à¸“à¸ˆà¸°à¸ªà¸²à¸¡à¸²à¸£à¸–:

1. âœ… à¹ƒà¸Šà¹‰ Kilo CLI à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ workflows à¸œà¹ˆà¸²à¸™ LLM
2. âœ… Desktop App à¸ªà¹ˆà¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¹ƒà¸«à¹‰ Kilo CLI â†’ à¹€à¸£à¸µà¸¢à¸ LLM
3. âœ… LLM à¸—à¸³à¸‡à¸²à¸™à¸œà¹ˆà¸²à¸™ Backend Proxy
4. âœ… Backend à¸ªà¹ˆà¸‡à¸•à¹ˆà¸­à¹„à¸›à¸¢à¸±à¸‡ LLM Provider (OpenRouter/OpenAI/Anthropic)
5. âœ… à¸£à¸±à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸à¸¥à¸±à¸šà¸¡à¸²à¹à¸ªà¸”à¸‡à¹ƒà¸™ Desktop App

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**
```bash
# Export env vars
export SMARTSPEC_BACKEND_URL=http://localhost:8000
export SMARTSPEC_PROXY_TOKEN=dev-token-smartspec-2026

# Run workflow
python -m ss_autopilot.cli_enhanced /workflow_name "your question here"
```

**à¸«à¸£à¸·à¸­à¸œà¹ˆà¸²à¸™ Desktop App:**
1. à¹€à¸›à¸´à¸” http://localhost:1420
2. à¹„à¸›à¸«à¸™à¹‰à¸² "Kilo CLI"
3. à¸žà¸´à¸¡à¸žà¹Œ: `/workflow_name your question here`
4. à¸à¸” Run

---

**Created:** 2026-01-09
**Updated:** 2026-01-09
**Version:** 1.0.0
**Status:** âœ… Production Ready
